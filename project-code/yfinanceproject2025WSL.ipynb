{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta \n",
    "\n",
    "import yfinance as yf\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "\n",
    "from matplotlib.dates import date2num\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CL=F\n",
      "2025-03-18 19:16:33.921778\n",
      "2020-03-19 19:16:33.921778\n"
     ]
    }
   ],
   "source": [
    "#set the ticker \n",
    "ticker = \"CL=F\"\n",
    "print(ticker)\n",
    "\n",
    "#set start and end date\n",
    "end_date = datetime.today()\n",
    "start_date = end_date - timedelta(days = 5*365)\n",
    "\n",
    "print(end_date)\n",
    "print(start_date)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([( 'Close', 'CL=F'),\n",
      "            (  'High', 'CL=F'),\n",
      "            (   'Low', 'CL=F'),\n",
      "            (  'Open', 'CL=F'),\n",
      "            ('Volume', 'CL=F')],\n",
      "           names=['Price', 'Ticker'])\n",
      "Price            Open       High        Low      Close   Volume\n",
      "Ticker           CL=F       CL=F       CL=F       CL=F     CL=F\n",
      "Date                                                           \n",
      "2020-03-19  22.299999  27.709999  21.360001  25.219999   136722\n",
      "2020-03-20  24.730000  27.889999  19.459999  22.430000  1133808\n",
      "2020-03-23  22.520000  24.070000  20.799999  23.360001   852951\n",
      "2020-03-24  23.870001  25.160000  23.090000  24.010000   659697\n",
      "2020-03-25  24.370001  25.240000  22.910000  24.490000   618725\n",
      "Price            Open       High        Low      Close  Volume\n",
      "Ticker           CL=F       CL=F       CL=F       CL=F    CL=F\n",
      "Date                                                          \n",
      "2025-03-11  65.949997  67.169998  65.290001  66.250000  222511\n",
      "2025-03-12  66.620003  67.879997  66.150002  67.680000  246675\n",
      "2025-03-13  67.690002  67.940002  66.370003  66.550003  268590\n",
      "2025-03-14  66.779999  67.480003  66.589996  67.180000  180495\n",
      "2025-03-17  67.349998  68.370003  67.250000  67.580002  180495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#save the data from yfinance to a dataframe\n",
    "oil_5y_df = pd.DataFrame()\n",
    "\n",
    "#valid period: 1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max\n",
    "#period= '1d'\n",
    "\n",
    "#set the interval: 1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo\n",
    "interval = '1d'\n",
    "\n",
    "#download specific information on stock\n",
    "data = yf.download(ticker, start=start_date, end=end_date, interval=interval)\n",
    "print(data.columns)\n",
    "\n",
    "#items included in our data frame\n",
    "oil_5y_df = data[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "\n",
    "#print \n",
    "print(oil_5y_df.head())\n",
    "print(oil_5y_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the data to the local path \n",
    "#output_folder = r\"Enter your path to save file\"\n",
    "\n",
    "output_file = os.path.join(output_folder, 'oil_5y_prices.xlsx')\n",
    "oil_5y_df.to_excel(output_file)\n",
    "\n",
    "\n",
    "#---------Download as a CSV file-------\n",
    "#from google.colab import files\n",
    "#df.to_csv('output.csv', encoding = 'utf-8-sig') \n",
    "#files.download('output.csv')\n",
    "\n",
    "#---------Save as  CSV to Google Drive --------#\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#path = '/content/drive/My Drive/output.csv'\n",
    "#with open(path, 'w', encoding = 'utf-8-sig') as f:\n",
    "#  df.to_csv(f)\n",
    "\n",
    "# ---------- Save as a Google Spreadsheet to Google Drive -------- #\n",
    "#!pip install gspread\n",
    "#from google.colab import auth\n",
    "#from google.auth import default\n",
    "#import gspread\n",
    "#import pandas as pd\n",
    "#Auth\n",
    "#auth.authenticate_user()\n",
    "#creds, _ = default()\n",
    "#gc = gspread.authorize(creds)\n",
    "#spreadsheet_key = 'my_spreadsheet_key'\n",
    "#workbook = gc.open_by_key(spreadsheet_key)\n",
    "#workbook.values_update(\n",
    "#  'sheet!A1',\n",
    "#  params={\n",
    "#      'valueInputOption': 'USER_ENTERED'\n",
    "#  },\n",
    "#  body={\n",
    "#      'values': [df.columns.values.tolist()] + df.values.tolist()\n",
    "#  }\n",
    "#)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reimport excel as new dataframe\n",
    "df = pd.read_excel('oil_5y_prices.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1259</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258.000000</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1259</td>\n",
       "      <td>1108.000000</td>\n",
       "      <td>1094.000000</td>\n",
       "      <td>1115.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>1254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2025-03-18 00:00:00</td>\n",
       "      <td>76.599998</td>\n",
       "      <td>79.900002</td>\n",
       "      <td>70.129997</td>\n",
       "      <td>70.099998</td>\n",
       "      <td>389325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Price         Open         High          Low  \\\n",
       "count                  1259  1258.000000  1258.000000  1258.000000   \n",
       "unique                 1259  1108.000000  1094.000000  1115.000000   \n",
       "top     2025-03-18 00:00:00    76.599998    79.900002    70.129997   \n",
       "freq                      1     4.000000     6.000000     4.000000   \n",
       "\n",
       "              Close  Volume  \n",
       "count   1258.000000    1258  \n",
       "unique  1106.000000    1254  \n",
       "top       70.099998  389325  \n",
       "freq       4.000000       2  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1259 entries, 0 to 1258\n",
      "Data columns (total 6 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Price   1259 non-null   object\n",
      " 1   Open    1258 non-null   object\n",
      " 2   High    1258 non-null   object\n",
      " 3   Low     1258 non-null   object\n",
      " 4   Close   1258 non-null   object\n",
      " 5   Volume  1258 non-null   object\n",
      "dtypes: object(6)\n",
      "memory usage: 59.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price', 'Open', 'High', 'Low', 'Close', 'Volume']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price     0\n",
       "Open      1\n",
       "High      1\n",
       "Low       1\n",
       "Close     1\n",
       "Volume    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Price     1259\n",
       "Open      1108\n",
       "High      1094\n",
       "Low       1115\n",
       "Close     1106\n",
       "Volume    1254\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#look for negative values\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mDate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m.filter(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[33m'\u001b[39m\u001b[33mAdj Close\u001b[39m\u001b[33m'\u001b[39m] < \u001b[32m0\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finance_env/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finance_env/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/finance_env/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Date'"
     ]
    }
   ],
   "source": [
    "#look for negative values\n",
    "print(df.groupby('Date').filter(lambda x: x['Adj Close'] < 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the index to Date\n",
    "df = df.set_index('Date')\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot all the close prices \n",
    "df[['Open','High','Low', 'Close','Adj Close']].plot(figsize=(12,7))\n",
    "\n",
    "#show legend \n",
    "plt.legend()\n",
    "\n",
    "#define label for the title of figure\n",
    "plt.title(\"DataSet Plot\", fontsize=16)\n",
    "\n",
    "#define label for x and y axis\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "\n",
    "#plot gridlines\n",
    "plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CandleStick Chart of Weekly Data\n",
    "import mplfinance as mpf\n",
    "\n",
    "#resample to weekly data \n",
    "weekly_data = df.resample('W').agg({'Open': 'first',\n",
    "                                    'High': 'max',\n",
    "                                    'Low': 'min',\n",
    "                                    'Close': 'last',\n",
    "                                    'Volume': 'first'})\n",
    "\n",
    "mpf.plot(weekly_data, \n",
    "         type='candle', \n",
    "         style='yahoo', \n",
    "         volume=True, \n",
    "         title=\"Candlestick Chart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Adj Close Price 1\n",
    "\n",
    "df['Adj Close'].plot(figsize=(10,5))\n",
    "\n",
    "#define label and for title for figure\n",
    "plt.title('Adjusted Close Price of %s 5year' %ticker, fontsize=16)\n",
    "\n",
    "#define labels for x and y axis \n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "\n",
    "#plot grid lines \n",
    "plt.grid(which=\"major\", color='k', linestyle='-.', linewidth=0.5)\n",
    "\n",
    "#show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets select 1 year of time series data\n",
    "df['year'] = df.index.year\n",
    "selected_year = 2020\n",
    "selected_data = df[df['year'] == selected_year]\n",
    "\n",
    "# Convert 'Date' column to datetime format\n",
    "selected_data.index = pd.to_datetime(selected_data.index)\n",
    "\n",
    "# Extract month information from the 'Date' column\n",
    "selected_data['month'] = selected_data.index.month\n",
    "\n",
    "#time series plot\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.lineplot(x=selected_data.index, y='Adj Close', hue='month', data=selected_data, palette='viridis')\n",
    "\n",
    "plt.title(f'Adjusted Close Prices for {selected_year}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adjusted Close Prices')\n",
    "plt.legend(title='month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Organize the data in groups\n",
    "df['year'] = df.index.year\n",
    "df['month'] = df.index.month\n",
    "df['day'] = df.index.day\n",
    "\n",
    "\n",
    "# Grouping by year and month and summing up the values\n",
    "grouped_data = df.groupby(['year', 'month']).sum()\n",
    "\n",
    "print(grouped_data)\n",
    "\n",
    "#Create bar chart using Seaborn\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='month', y='Volume', hue='year', data=df, palette='viridis')\n",
    "\n",
    "plt.title('Sales Volume by Year and Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Sales Volume')\n",
    "plt.legend(title='Year', loc='upper right', bbox_to_anchor=(1.15,1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get unique months in the DataFrame\n",
    "\n",
    "unique_months = df['month'].unique()\n",
    "\n",
    "#create a line plot for each month - using Seaborn\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "for month in unique_months:\n",
    "    selected_data = df[df['month'] == month]\n",
    "    sns.lineplot(x='year', y='Volume',data=selected_data, label=f'month{month}', marker='o')\n",
    "    #customize the plot\n",
    "    plt.title('Sales Volume over the Years for each Month')\n",
    "    plt.xlabel('Year')\n",
    "    plt.ylabel('Sales Volume')\n",
    "    plt.legend(title='Month', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "#show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a histogram for each month\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "\n",
    "for i, month in enumerate(unique_months, 1):\n",
    "    plt.subplot(3,4,i) #Adjust subplot\n",
    "    sns.histplot(df[df['month'] == month]['Volume'], bins=10, kde=True)\n",
    "    plt.title(f'Sales Volume - Month{month}')\n",
    "    plt.xlabel('Volume')\n",
    "    plt.ylabel('Frequency')\n",
    "\n",
    "#adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#year & month wise box plot \n",
    "\n",
    "#df['year'] = [d.year for d in df.year]\n",
    "#df['month'] = [d.strftime('%b') for d in df.month]\n",
    "years = df['year'].unique()\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(20,7), dpi=80)\n",
    "sns.boxplot(x='year', y='Adj Close', data=df, ax=axes[0])\n",
    "sns.boxplot(x='month', y='Adj Close',data=df.loc[~df.year.isin([2019,2024]), :])\n",
    "\n",
    "axes[0].set_title('Year-wise Box plot\\n(The Trend)', fontsize=18);\n",
    "axes[1].set_title('Month-wise Box Plot\\n(The Seasonality)', fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot total amount of sales per year\n",
    "yearlyVol = df.groupby(df.year)['Volume'].sum()\n",
    "\n",
    "print(yearlyVol)\n",
    "\n",
    "yearlyVol.plot(kind='bar', \n",
    "               title='Volume of Sales per Year',\n",
    "               ylabel='Total Volume',\n",
    "               xlabel='Year',\n",
    "               figsize=(10,6))\n",
    "\n",
    "\n",
    "#rotate x-axis ticks vertically\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "#create total amount of sales per year - using Seaborn \n",
    "plt.figure(figsize=(10,7))\n",
    "sns.barplot(x='year', y='Volume', data=df, palette='viridis')\n",
    "\n",
    "plt.title('Total Volume per Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Volume')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns to our dataframe %change and Range\n",
    "df['% Change'] = (df['Adj Close']/df['Adj Close'].shift(1))-1\n",
    "df['Range'] = df['High'] - df['Low']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trend Analysis - calculate rolling averages 20 and 50 Day\n",
    "df['Adj Close'].plot(label='Original', legend=True, figsize=(12,7))\n",
    "df['Adj Close'].rolling(window=20).mean().plot(label='20 Day MA', legend=True)\n",
    "df['Adj Close'].rolling(window=50).mean().plot(label='50 Day MA', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now focus only on the crude oil value- we will call that as close price.\n",
    "From your plots identify a value of K to define a “big jump” in the stock\n",
    "price. Identify the dates for which the close price is K “points” less than\n",
    "the close price of the previous day (for example, if K = 100, you will find\n",
    "the dates for which the close price is 100 points below the previous business\n",
    "day. An example of that: suppose the close price for Jan 2 is 500.2 and\n",
    "close price for Jan 3 (or the next business day) is 398.7. Then you will\n",
    "identify Jan 3.) These dates (e.g. Jan 3 in the last example) will be called\n",
    "“crash-like dates”. Corresponding close price will be called “crash-like\n",
    "close price” (e.g. 398.7 in the last example). NOTE: ONLY downward\n",
    "jump of size K corresponds to “crash”- NOT the upward jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate daily price changes\n",
    "df['Price Change'] = df['Adj Close'].diff()\n",
    "\n",
    "#set threshold value for a big jump\n",
    "K = 2\n",
    "\n",
    "#find date with big jump\n",
    "crash_dates = df[df['Price Change'] <= -K]\n",
    "\n",
    "#plot stock prices \n",
    "plt.figure(figsize=(12,6))\n",
    "#plt.plot(df.index, df['Adj Close'], label ='Close Price', marker='o')\n",
    "plt.scatter(crash_dates.index, crash_dates['Adj Close'], color='red', label=f'Big Jumps (<= -{K}points)')\n",
    "\n",
    "plt.title('Stock Price and Big Jumps')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adj Close Prices')\n",
    "plt.legend()\n",
    "plt.show() \n",
    "\n",
    "#display dates with big jump\n",
    "print(f'Dates with a big jump (<= -{K} points):')\n",
    "print(crash_dates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. \n",
    "Create a new data-frame from the old one: “features” (columns) will be\n",
    "10 consecutive close prices. For example: if the close prices are\n",
    "a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13, a14, a15;\n",
    "then the first row of your dataset will contain\n",
    "a1, a2, a3, a4, a5, a6, a7, a8, a9, a10;\n",
    "second row\n",
    "a2, a3, a4, a5, a6, a7, a8, a9, a10, a11;\n",
    "third row\n",
    "a3, a4, a5, a6, a7, a8, a9, a10, a11, a12;\n",
    "fourth row\n",
    "a4, a5, a6, a7, a8, a9, a10, a11, a12, a13;\n",
    "1\n",
    "fifth row\n",
    "a5, a6, a7, a8, a9, a10, a11, a12, a13, a14;\n",
    "and final row\n",
    "a6, a7, a8, a9, a10, a11, a12, a13, a14, a15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of consecutive close prices to include in each row\n",
    "consecutive_prices = 10\n",
    "\n",
    "features_df = pd.DataFrame({\n",
    "    f'Adj Close_{i}': df['Adj Close'].shift(-i) for i in range(consecutive_prices)\n",
    "})\n",
    "\n",
    "features_df=features_df.dropna()\n",
    "\n",
    "print(\"New DataFrame 'feature':\")\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. \n",
    "Create a new target column for the new data-frame (as created in the last\n",
    "step) as follows: C = 1 (abbreviation of “Crash=1”) for those set of 10\n",
    "close prices that immediately precede to a “crash-like close price” and/or\n",
    "contains a “crash-like close price”. Otherwise label the target column by\n",
    "C = 0 (abbreviation of “Crash=0”).\n",
    "For example: suppose we identified a13 as the only “crash-like close price”.\n",
    "Then the C = 0 for the first row a1, a2, a3, a4, a5, a6, a7, a8, a9, a10; and the\n",
    "second row a2, a3, a4, a5, a6, a7, a8, a9, a10, a11. But C = 1 for all the other\n",
    "rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df['C'] = 0\n",
    "\n",
    "for crash_date in crash_dates.index:\n",
    "    #check if crash_date is in the index\n",
    "    \n",
    "    if crash_date in features_df.index:\n",
    "        #convert timestamp to integer index\n",
    "        crash_index = features_df.index.get_loc(crash_date)\n",
    "    \n",
    "    #set 'C' as 1 for set of 10 close prices that contain a crash-like close price\n",
    "    features_df.iloc[crash_index - consecutive_prices + 1 : crash_index + 1, features_df.columns.get_loc('C')] = 1\n",
    "    \n",
    "# Print the updated DataFrame with the target column 'C'\n",
    "print(\"Updated DataFrame 'features_df' with target column 'C':\")\n",
    "print(features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Now run all the “classification algorithms” (supervised learning) for ma\n",
    "chine learning that we studied in class. Input: Close prices for ten con\n",
    "secutive days. Output: C-value (0 or 1). Check the classification report\n",
    " and confusion matrix in each cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C' is the target column\n",
    "X = features_df.drop('C', axis=1)\n",
    "y = features_df['C']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Logistic Regression\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(model, y_true, y_pred):\n",
    "    print(f\"-------- {model.__class__.__name__} --------\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Evaluate Logistic Regression\n",
    "evaluate_model(logistic_regression, y_test, y_pred_lr)\n",
    "\n",
    "# Evaluate Decision Tree\n",
    "evaluate_model(decision_tree, y_test, y_pred_dt)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "evaluate_model(random_forest, y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Neural Network\n",
    "neural_network = MLPClassifier(random_state=42)\n",
    "neural_network.fit(X_train, y_train)\n",
    "y_pred_nn = neural_network.predict(X_test)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "evaluate_model(neural_network, y_test, y_pred_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maximum Drawdown \n",
    "def max_drawdown(returns):\n",
    "    \"\"\"\n",
    "    Calculate the maximum drawdown of a series of returns.\n",
    "    \n",
    "    Parameters:\n",
    "    returns (array-like): Array or Series of returns.\n",
    "\n",
    "    Returns:\n",
    "    float: Maximum drawdown value.\n",
    "    \"\"\"\n",
    "    cumulative_returns = np.cumprod(1 + returns)\n",
    "    previous_peaks = np.maximum.accumulate(cumulative_returns)\n",
    "    drawdowns = (cumulative_returns - previous_peaks) / previous_peaks\n",
    "    max_drawdown = np.min(drawdowns)\n",
    "    return max_drawdown\n",
    "\n",
    "# Define the number of epochs\n",
    "epochs = 20000 \n",
    "\n",
    "# Logistic Regression\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train, y_train)\n",
    "y_pred_lr = logistic_regression.predict(X_test)\n",
    "returns_lr = y_test == y_pred_lr\n",
    "max_drawdown_lr = max_drawdown(returns_lr.astype(int))\n",
    "print(\"Maximum Drawdown for Logistic Regression:\", max_drawdown_lr)\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "returns_dt = y_test == y_pred_dt\n",
    "max_drawdown_dt = max_drawdown(returns_dt.astype(int))\n",
    "print(\"Maximum Drawdown for Decision Tree:\", max_drawdown_dt)\n",
    "\n",
    "# Random Forest\n",
    "random_forest = RandomForestClassifier()\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "returns_rf = y_test == y_pred_rf\n",
    "max_drawdown_rf = max_drawdown(returns_rf.astype(int))\n",
    "print(\"Maximum Drawdown for Random Forest:\", max_drawdown_rf)\n",
    "\n",
    "# Neural Network\n",
    "neural_network = MLPClassifier(random_state=42)\n",
    "neural_network.fit(X_train, y_train)\n",
    "y_pred_nn = neural_network.predict(X_test)\n",
    "returns_nn = y_test == y_pred_nn\n",
    "max_drawdown_nn = max_drawdown(returns_nn.astype(int))\n",
    "print(\"Maximum Drawdown for Neural Network:\", max_drawdown_nn)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
